{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'KnowledgeGraph' has no attribute '__file__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01margparse\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m curPath \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(\u001b[43mKnowledgeGraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__file__\u001b[39;49m))\n\u001b[1;32m      7\u001b[0m rootPath \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msplit(curPath)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      8\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(rootPath)\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'KnowledgeGraph' has no attribute '__file__'"
     ]
    }
   ],
   "source": [
    "from src.knowledge_graph import KnowledgeGraph\n",
    "\n",
    "import argparse\n",
    "import os, sys\n",
    "\n",
    "curPath = os.path.abspath(os.path.dirname(KnowledgeGraph.__file__))\n",
    "rootPath = os.path.split(curPath)[0]\n",
    "sys.path.append(rootPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu/MBE/data/WN-MBE'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = \"WN-MBE\"\n",
    "os.path.join(os.getcwd(), 'data', dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='MBE')\n",
    "\n",
    "parser.add_argument('--bandwidth', type=int, default=300,\n",
    "                    help='maximum number of outgoing edges to explore at each step (default: 300)')\n",
    "parser.add_argument('--model', type=str, default='point',\n",
    "                    help='knowledge graph QA model (default: point)')\n",
    "parser.add_argument('--data_dir', type=str, default=os.path.join(os.getcwd(), 'data', dataset),\n",
    "                    help='directory where the knowledge graph data is stored (default: None)')\n",
    "parser.add_argument('--emb_dim', type=int, default=100, metavar='E',\n",
    "                    help='embedding dimension (default: 100)')\n",
    "parser.add_argument('--emb_dropout_rate', type=float, default=0.3,\n",
    "                    help='Knowledge graph embedding dropout rate (default: 0.3)')\n",
    "parser.add_argument('--batch_num', type=int, default=6,\n",
    "                    help='the number of new batch and original KG (default: 5+1=6)')\n",
    "parser.add_argument('--argcn', type=bool, default=True,\n",
    "                    help='If true, the model will use ARGCN to generate embeddings (default: True)')\n",
    "parser.add_argument('--now_batch', type=int, default='0',\n",
    "                    help='indicate the currently used data(train: 0, valid: 1; new batch: 2-6)')\n",
    "parser.add_argument('--aug_link', type=bool, default=True,\n",
    "                    help='If true, the model will use augmentation links (default: True)')\n",
    "parser.add_argument('--use_action_space_bucketing', type=bool, default=True,\n",
    "                    help='bucket adjacency list by outgoing degree to avoid memory blow-up (default: True)')\n",
    "parser.add_argument('--bucket_interval', type=int, default=10,\n",
    "                    help='adjacency list bucket size (default: 32)')\n",
    "\n",
    "args, unknown = parser.parse_known_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "No CUDA GPUs are available",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m kg \u001b[38;5;241m=\u001b[39m \u001b[43mKnowledgeGraph\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/MBE/src/knowledge_graph.py:69\u001b[0m, in \u001b[0;36mKnowledgeGraph.__init__\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_object_vectors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     68\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m** Create \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m knowledge graph **\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(args\u001b[38;5;241m.\u001b[39mmodel))\n\u001b[0;32m---> 69\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_graph_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_all_answers(args\u001b[38;5;241m.\u001b[39mdata_dir)\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_all_answers_new_batch(args\u001b[38;5;241m.\u001b[39mdata_dir)\n",
      "File \u001b[0;32m~/MBE/src/knowledge_graph.py:137\u001b[0m, in \u001b[0;36mKnowledgeGraph.load_graph_data\u001b[0;34m(self, data_dir)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;66;03m# logging.info('Sanity check: {} relations loaded'.format(len(self.relation2id)))\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \n\u001b[1;32m    135\u001b[0m \u001b[38;5;66;03m# Load graph structures\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpoint\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvectorize_action_space\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/MBE/src/knowledge_graph.py:516\u001b[0m, in \u001b[0;36mKnowledgeGraph.vectorize_action_space\u001b[0;34m(self, data_dir)\u001b[0m\n\u001b[1;32m    514\u001b[0m         num_facts_saved_in_action_table \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(action_space)\n\u001b[1;32m    515\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m action_space_buckets_discrete:\n\u001b[0;32m--> 516\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space_buckets[key] \u001b[38;5;241m=\u001b[39m \u001b[43mvectorize_action_space\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m            \u001b[49m\u001b[43maction_space_buckets_discrete\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbucket_interval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    519\u001b[0m     action_space_list \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/MBE/src/knowledge_graph.py:479\u001b[0m, in \u001b[0;36mKnowledgeGraph.vectorize_action_space.<locals>.vectorize_action_space\u001b[0;34m(action_space_list, action_space_size)\u001b[0m\n\u001b[1;32m    477\u001b[0m         p_space[i, j] \u001b[38;5;241m=\u001b[39m p\n\u001b[1;32m    478\u001b[0m         action_mask[i, j] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 479\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[43mint_var_cuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr_space\u001b[49m\u001b[43m)\u001b[49m, int_var_cuda(e_space), var_cuda(c_space), int_var_cuda(p_space)), var_cuda(action_mask)\n",
      "File \u001b[0;32m~/MBE/src/utils/ops.py:122\u001b[0m, in \u001b[0;36mint_var_cuda\u001b[0;34m(x, requires_grad)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mint_var_cuda\u001b[39m(x, requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlong\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/cuda/__init__.py:298\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[1;32m    297\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLAZY\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 298\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    302\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No CUDA GPUs are available"
     ]
    }
   ],
   "source": [
    "kg = KnowledgeGraph(args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
